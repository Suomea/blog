---
comments: true
---
# 并发控制
## 锁
通过对多线程的介绍，能够到了并发编程一个最基本的问题：即希望原子性的执行一系列指令，但是由于单处理器的中断（或者多个线程在多个处理器上执行），我们做不到。

通过锁（lock），直接解决这一问题。在程序代码中加锁，放在临界区周围，保证临界区能够像单条原子指令一样执行。
### 如何实现锁
首先需要明确的是，锁的实现需要硬件和操作系统的帮助。各种计算机体系结构的指令集都包含一些相似的硬件原语，这里不研究这些指令是如何实现的，只研究如何使用它们来实现锁这样的互斥原语。操作系统正是在这种基础指令的支持下完善发展，支持实现复杂成熟锁库的。

### 评价锁
在实现锁之前，应该明确目标，即如何评价一种锁实现的效果，应该为此设立一些明确的目标。

- 正确性，锁是否能够完成它的基本任务，即提供互斥。这是最基本的，锁是否有效，能够阻止多个线程进入临界区。
- 公平性，当锁可用时，是否每一个竞争线程有公平的机会抢到锁？用另一种极端的方式看这个问题是，是否有竞争的线程会饿死，一致无法获得锁？
- 性能，具体来说，是使用锁之后增加的时间开销。

### 简单的尝试
我们的想法很简单：用一个变量来标志锁是否被某些线程占用。

第一个线程进入临界区，调用 lock 函数，检查标志是否为 1（这里不是 1），然后设置标志为 1，表示线程持有该锁。结束临界区时，线程调用 unlock 函数，清除标志，表示锁未被持有。

线程在等待已经被持有的锁时，采用了自旋等待的技术（spin waiting），就是不停的检查锁标志的值。
```c
struct my_lock {
    int flag;
} mutex;

void init(struct my_lock *mutex) {
    mutex->flag = 0;
}

void lock(struct my_lock *mutex) {
    while (mutex->flag == 1)    // test the flag
        ;   // spain wait
    mutex->flag = 1;    // set the flag
}

void unlock(struct my_lock *mutex) {
    mutex->flag = 0;
}
```
遗憾的是这段代码有两个问题：正确性和性能。

**正确性问题**
一种是不可控的线程调度，因为 lock 函数加锁的逻辑分为两步并且线程的调度不可控，可能会导致两个线程同时加锁成功。我们需要可靠的原子操作（guaranteed atomic operations）来解决这个问题。

| Thread 1                          | Thread 2                                        |
| --------------------------------- | ----------------------------------------------- |
| test the flag; // 中断：切换到 Thread 2 |                                                 |
|                                   | test the flag; set the flag; // 中断：切换到 Thread 1 |
| set the flag;                     |                                                 |

另一种是线程模型（或者 CPU 缓存模型）使得变量缓存在线程本地（或者 CPU 缓存），导致即使一个线程加锁成功而另一个线程观察不到仍能加锁成功。可以通过总线加锁（LOCK# 信号和 LOCK 指令前缀）来解决这个问题。

同时为了使临界区的代码执行完成之后，所有的线程都能观察到临界区对状态的更新，一般使用内存屏障相关的指令来保证状态的可视性。需要注意这里的状态可视性和锁变量的可视性要区分开。

**性能问题**
性能问题主要是自旋等待在等待其它线程释放锁的时候会浪费 CPU 时间。尤其是在单处理器上，一个等待线程等待的目标线程甚至无法运行！

#### 硬件原语 test-and-set
尽管简单的尝试想法很好，但是没有硬件的支持是无法实现的。幸运的是，一些系统提供了这一指令，支持基于这种概念创建简单的锁。

在 x86 上，是 xchg（atomic change，原子交换）指令，该指令自动带有 LOCK 语义，通常称为测试并设置指令（test-and-set）。使用 C 代码来定义测试并设置指令做了什么。
```c
int TestAndSet(int *old_ptr, int new) {
    int old = *old_ptr;
    *old_ptr = new;
    return old;
}
```

使用 xchg 的简单自旋锁如下：
```c
typedef struct my_lock {
    int flag;
} mutex;

void init(struct my_lock *mutex) {
    mutex->flag = 0;
}

void lock(struct my_lock *mutex) {
    while(TestAndSet(mutex->flag, 1) == 0)
        ;
}

void unlock(struct my_lock *mutex) {
    mutex->flag = 0;
}
```
这种锁的实现称为自旋锁，是一种最简单的锁，一值自旋，直到锁可用。

#### 硬件原语 compare-and-swap
另一个硬件原语是比较并交换指令，x86 架构中是 cmpxchgl 指令。C 语言伪代码如下：
```c
int CompareAndSwap(int *ptr, int expected, int new) {
    int actual = *ptr;
    if(actual == expected) {
        *ptr = new;
    }
    return actual;
}
```
有了比较并交换指令，就可以实现一个锁，类似于测试并设置那样。例如，只需要用下面的代码替换 lock() 函数：
```c
void lock(my_lock *mutex) {
    while(CompareAndSwap(mutex->flag, 0, 1) == 0) {
        ;
    }
}
```
下面是通过 cmpxchgl 指令实现锁并通过测试的真实示例，代码中使用到了内联汇编的语法：
```c
#include <stdio.h>
#include <assert.h>
#include <pthread.h>

char CompareAndSwap(int *ptr, int old, int new) {
    unsigned char ret;

    __asm__ __volatile__ (
            " lock\n"   // lock
            " cmpxchgl %2, %1\n"    // cmpxchgl
            " sete %0\n"    // sete
            : "=q" (ret), "=m" (*ptr)   // 输出
            : "r" (new), "a" (old)  // 输入
            : "memory");    // memory
    return ret;
}

struct my_lock {
    int flag;
} mutex;

void init(struct my_lock *mutex) {
    mutex->flag = 0;
}

void lock(struct my_lock *mutex) {
    while(CompareAndSwap(&mutex->flag, 0, 1) == 0) {
        ;
    }
}

void unlock(struct my_lock *mutex) {
    mutex->flag = 0;
}

int counter = 0;

void *thread_function(void *arg);

int main() {
    pthread_t a_thread, b_thread;
    int rc;

    init(&mutex);

    printf("main: begin\n");

    rc = pthread_create(&a_thread, NULL, thread_function, "A"); assert(rc == 0);
    rc = pthread_create(&b_thread, NULL, thread_function, "B"); assert(rc == 0);

    rc = pthread_join(a_thread, NULL); assert(rc == 0);
    rc = pthread_join(b_thread, NULL); assert(rc == 0);

    printf("main: done with both (counter = %d)\n", counter);

    return 0;
}

void *thread_function(void *arg) {
    printf("%s: begin\n", (char *) arg);
    for(int i = 0; i < 1000000; i ++) {
        lock(&mutex);
        counter ++;
        unlock(&mutex);
    }
    printf("%s: done\n", (char *) arg);

    return NULL;
}
```
这里解释一下内联汇编部分的代码。

1. `lock` 标识锁定内存总线，并且保证后的指令原子式的执行。
2. 输入部分 `"a" (old)` 表示将 `old` 变量的值放入 `eax` 寄存中作为汇编指令的输入。`a` 表示 `eax` 寄存器。
3. 输入部分 `"r" (new)` 表示将 `new` 变量的值使用一个通用寄存器存放，作为汇编指令的输入。`r` 表示任意的一个通用寄存器。占位 `%2`。
4. 输出部分 `"=m" (*ptr)` 表示使用内存地址（`*ptr`）作为汇编指令的输出，`m` 表示内存地址，`=` 表示输出表达式操作是只写的。占位 `%1`。
5. 输出部分 `"=q" (ret)` 暂时没有搞明白，大致就是输出结果放到 `ret` 中。占位 `%0`。
6. `cmpxchgl` 指令比较 `eax` 寄存的值（也就是 `old` 变量的值）与 `%1` 占位的值（也就是 `*ptr` 的值），如果相等，将 `%2` 占位的值（也就是 `new` 变量的值）
    赋值给 `%1` 占位（也就是 `*ptr`）同时标志寄存器 `ZF` 位置 `1`；否则，将 `%1` 占位的值赋值给 `eax`，并且将标志寄存器 `ZF` 位置 `0`。
7. `sete` 指令，如果标志寄存器 `ZF` 位为 `1` 那么设置 `%0` 占位的值（也就是 `ret` 的值）为 `1`。
8. `memory` 向 GCC 声明：在这里内存发生或者可能发生可改变。那么 GCC 会保证在此内联汇编之前如果某个内存的内容被读取，那么在内联汇编之后如果需要使用
   使用这个内存处的内容，就会直接从内存读取而不是使用缓存，从而实现内存屏障的效果。

#### 硬件原语 fetch-and-add
获取并增加指令能够原子地返回特定地址的旧值，并且让该值自增一。使用该指令也能实现简单的自旋锁，这里我们增加一点玩法，在自旋的基础上实现公平性。
```c
int FetchAndAdd(int *ptr) {
    int old = *ptr;
    *ptr ++;
    return old;
}

typedef struct my_lock {
    int ticket;
    int turn;
} mutex;

void init(struct my_lock *mutex) {
    mutex->ticket = 0;
    mutex->turn = 0;
}

void lock(struct my_lock *mutex) {
    int my_turn = FetchAndAdd(&mutex->ticket);
    while(mutex->turn != my_turn) {
        ;
    }
}

void unlock(struct my_lock *mutex) {
    FetchAndAdd(&mutex->turn);
}
```
不同于之前的方法，这种方式能够保证只要一个线程获取了 ticket 值，它最终会被调度。

### 如何解决过多的自旋
通过上述硬件原语，已经实现了正确、公平的锁，但是通过使用自旋等待实现的锁可能会造成性能问题。  

在并发量较少且临界区能够快速执行完毕的情况下 可能问题不明显；在果并发量比较高或者临界区耗时比较久的情况下，如果临界区的线程（获得锁的线程）发生上下文切换，那么其它线程即使获得 CPU 时间
也只能一直自旋等待，浪费了 CPU 时间。

#### 线程让步
一种简单的的方法使在线程要自旋的时候让出 CPU，参考下面的代码：
```c
void lock(my_lock *mutex) {
    while(TestAndSet(&mutex->flag, 1) == 1)
	    yield();
}
```

在这种方法中，假定操作系统提供原语 `yield()`，线程可以调用它主动放弃 CPU，让其它线程运行。

在许多线程竞争同一把锁的情况下，线程让步就不太好了。比如 100 个线程竞争一把锁，在这种情况下，一个线程持有锁，在释放锁之前，其它 99 个线程分别调用 `lock()`，发现锁被抢占，然后让出 CPU。问题是，竞争线程虽然让出了 CPU，但是让出之后处于就绪状态，仍能获取 CPU 时间。那么上下文切换，甚至极端情况下一个线程可能一直处于让出循环，锁的性能仍然很低。

#### 休眠代替自旋
自旋和线程让步真正的问题是存在太多的偶然性，导致在较多线程时，锁的性能较低。因此，可以施加一些控制，并且在决定释放锁时定能抢到锁。为了做到这一点，需要操作系统提供更多的支持，并需要一个队列来保存等待锁的线程。

Solaris 系统提供了两个系统调用：park() 能够让调用线程休眠，unpark(threadID) 则会唤醒 threadID 标识的线程。

示例代码：
```c
typedef struct lock_t {
    int flag;
    int guard;
    queue_t *q;
} lock_t;

void lock_init(lock_t *m) {
    m->flag = 0;
    m->guard = 0;
    queue_init(m->q);
}

void lock(lock_t *m) {
    while(TestAndSet(&m->guard, 1) == 1)
        ;   // acquire guard lock by spinning

    if(m->flag == 0) {
        m->flag = 1;
        m->guard = 0;
    } else {
        queue_add(m->q, gettid());
        m->guard = 0;
        park();
    }
}

void unlock(lock_t *m) {
    while(TestAndSet(&m->guard, 1) == 1)
        ; // acquire guard lock by spinning
    
    if(queue_empty(m->q)) {
        m->flag = 0;
    } else {
        unpark(queue_remove(m->q));
    }

    m->guard = 0;
}
```

上述代码 guard 基本上起到了自旋锁的作用，围绕着 flag 和队列操作。线程设置 guard 成功后，会设置 flag，之后释放 guard。新的线程设置 guard 成功之后会判断 flag 的值，判断当前是否有其它线程已经获得锁，如果有则 park() 进入休眠状态，等待 unpark() 唤醒。

当唤醒另一个线程时，flag 并没有设置为 0。线程被唤醒时，就像是从 park() 调用返回。就像把锁从释放的线程传递给下一个获得锁的线程，直到队列为空才将 flag 设置为 0。

在 park() 调用之前，如果不凑巧，一个线程将要 park()，此时切换到另一个线程，比如持有锁的线程，执行了释放锁的代码。那么前一个线程的 park() 将会永远休眠。这种问题称为唤醒/等待竞争（wakeup/waiting race）， Solaris 通过增加 setpark() 系统调用来解决这一问题。通过 setpark()，一个线程表明自己马上要 park，如果刚好另一个线程被调度，并且调用了 unpark()，那么后续的 park() 调用会直接返回，而不是一直睡眠。lock() 函数可以做一点小修改：
```c
queue_add(m->q, gettid());
setpark();
m->guard = 0;
park();
```

这段代码还有一些问题，如何确保 flag 和 guard 以及 queue_t 的可视性？

### Linux futex
Linux 提供了快速用户空间互斥量（fast userspace mutex，futex），每个 futex 都关联一个特定的物理内存位置，也有一个事先建好的内核队列。

有两个系统调用：`futex_wait(address，expected)` ，如果 `address` 处的值等于 `expected`，就会让线程睡眠，否则立刻返回；`futex_wake(address)` 唤醒等待队列中的一个线程。

futex 利用一个整数，同时记录锁是否被持有（整数的最高位），以及等待锁的个数（整数的其余所有位）。因此，如果锁是负的，它就被持有。

```c
void mutex_lock(int *mutex)
{
    int v;
    /* Bit 31 was clear, we got the mutex (the fastpath) */
    if (atomic_bit_test_set(mutex, 31) == 0)
        return;
    atomic_increment(mutex);
    while (1)
    {
        if (atomic_bit_test_set(mutex, 31) == 0)
        {
            atomic_decrement(mutex);
            return;
        }
        /* We have to waitFirst make sure the futex value
        we are monitoring is truly negative (locked). */
        v = *mutex;
        if (v >= 0)
            continue;
        futex_wait(mutex, v);
    }
}

void mutex_unlock(int *mutex)
{
    /* Adding 0x80000000 to counter results in 0 if and
    only if there are not other interested threads */
    if (atomic_add_zero(mutex, 0x80000000))
        return;

    /* There are other threads waiting for this mutex,
    wake one of them up. */
    futex_wake(mutex);
}
```

`atomic_bit_test_set()` 函数将指定的位设置为 1，并返回原来的值。示例代码中将最高位设置为 1，成功表示获取锁，同时 `*mutex` 称为负数。

`atomic_add_zero()` 将两个数相加，并判断结果是不是 0。示例代码中该函数的作用是释放锁，并且如果结果等于 0 表示没有等待的线程，直接返回。

### 互斥量
可以使用 pthread 的互斥接口来保护数据，确保同一时间只有一个线程访问数据。互斥量（mutex）本质上是一把锁，在访问共享资源前对互斥量进行设置（加锁），在访问完成后释放互斥量（解锁）。

互斥变量是用 `pthread_mutex_t` 数据类型表示的。在使用互斥量之前，必须对它进行初始化，通过 `pthread_mutex_init` 函数。如果动态分配互斥量（例如，通过 maolloc 函数），在释放内存之前需要调用 `pthread_mutex_destory`。
```c
#include <pthread.h>

int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);

int pthread_mutex_destory(pthread_mutex_t *mutex);
```
要用默认的属性初始化互斥量，只需要 把 `attr` 设置 NULL。

对互斥量进行加锁，调用 `pthread_mutex_lock`。如果互斥量已经上锁，调用线程将阻塞直到互斥量被解锁。对互斥量解锁，需要调用 `pthread_mutex_unlock`。如果不希望线程被阻塞，可以使用 `pthread_mutex_trylock` 尝试对互斥量进行加锁。如果调用 `pthread_mutex_trylock` 时互斥量处于未锁住状态，那么 `pthread_mutex_trylock` 将锁住互斥量，不会出现阻塞直接返回 0，否则 `pthread_mutex_trylock` 就会失败，不能锁住互斥量，返回 `EBUSY`。
```c
#include <pthread.h>

int pthread_mutex_lock(pthread_mutex_t *mutex);

int pthread_mutex_trylock(pthread_mutex_t *mutex);

int pthread_mutex_unlock(pthread_mutex_t *mutex);
```

示例代码：
```c
#include <stdio.h>
#include <pthread.h>

struct foo{
    int f_count;
    pthread_mutex_t f_lock;
    int f_id;
};

struct foo *foo_alloc(int id) {
    struct foo *fp;
    if((fp = malloc(sizeof(struct foo))) != NULL) {
        fp->f_count = 1;
        fp->f_id = id;
        if(pthread_mutex_init(&fp->f_lock, NULL) != 0) {
            free(fp);
            return NULL;
        }
    }
    return fp;
}

void foo_hold(struct foo *fp) {
    pthread_mutex_lock(&fp->f_lock);
    fp->f_count ++;
    pthread_mutex_unlock(&fp->f_lock);
}
```

当线程试图获取一个已经加锁的互斥量时，`pthread_mutex_timedlock` 函数允许绑定线程阻塞时间。`pthread_mutex_timedlock` 函数与 `pthread_mutex_lock` 是基本等价的，但是在达到超时时间值时，`pthread_mutex_timedlock` 返回错误代码 `ETIMEDOUT`。
```
#include <pthread.h>
#include <time.h>

int pthread_mutex_timedlock(pthread_mutex_t *restrict mutex,
							const struct timespec *restrict tsptr);
```
### 读写锁
读写锁（reader-wirter lock）与互斥量类似，不过读写锁允许更高的并行性。互斥量要么是锁住状态，要么就是不加锁状态，而且一次只有一个线程可以对其加锁。读写锁可以有 3 种状态：读模式下加锁状态，写模式下加锁状态，不加锁状态。一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。

- 当读写锁是写加锁状态时，在这个锁被解锁之前，所有试图对这个锁加锁的线程都会被阻塞。

- 当读写锁在读加锁状态时，所有试图以读模式对它进行加锁的线程都可以得到访问权，但是任何希望以写模式对此锁进行加锁的线程都会阻塞，直到所有的线程释放它们的读锁为止。

- 当读写锁处于读模式加锁状态时，而这时有一个线程试图以写模式获取锁时，读写锁通常会阻塞随后的读模式锁请求。这样可以避免读模式锁长期占用，而等待的写模式锁请求一直得不到满足。

读写锁非常适合对于数据结构读的次数远大于写的情况。读写锁也叫做共享互斥锁（shared-exclusive lock）。当读写锁是读模式锁住时，就可以说成是以共享模式锁住的。当它是写模式锁住的时候，就可以说成是以互斥模式锁住的。

读写锁的初始化和销毁：
```c
#include <pthread.h>

int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr);

int pthread_rwlock_destory(pthread_rwlock_t *rwlock);
```

读写锁的加锁和解锁：
```c
#include <pthread.h>

int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
```

读写锁的非阻塞获锁版本。可以获取锁时，这两个函数返回 0。否则它们返回错误 EBUSY。
```c
#include <pthread.h>

int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock);
```

读写锁带有超时的加锁函数，如果超时到期没有获取到锁，这两个函数将返回 `ETIMEDOUT` 错误。
```c
#include <pthread.h>
#include <time.h>

int pthread_rwlock_timedrdlock(pthread_rwlock_t *restrict rwlock, const struct timespec *retrict tsptr);

int pthread_rwlock_timedwrlock(pthread_rwlock_t *restrict rwlock, const struct timespec *retrict tsptr);
```
## 条件变量
通过锁，能够实现互斥访问和原子性的执行一系列执行的愿望。然而，锁并不是并发程序设计所需的唯一原语。在一些情况下，线程需要检查某一条件满足之后，才会继续运行。例如，父线程检查子线程是否执行完毕，这种等待如何实现呢？

### `volatile` 实现等待
一种简单的实现等待的方式是 `volatile` 和自旋配合实现等待。比如 A 线程要等待 B 线程执行完毕，那么定义 `volatile int b_finish_flag = 0`，在线程 B 执行完毕之后，修改变量的值，A 线程一致自旋等待 B 完成。因为 `volatile` 关键字能够保证可视性。
示例代码：
```c
#include <stdio.h>
#include <pthread.h>

void *child(void *arg);

volatile int b_finish_flag = 0;

int main() {
    printf("A: begin\n");
    
    pthread_t b;
    pthread_create(&b, NULL, child, "B");
    
    while(b_finish_flag == 0)
        ;
    printf("A: end\n");
    return 0;
}

void *child(void *arg) {
    printf("hello, i'm %s\n", arg);
    b_finish_flag = 1;
    return NULL;
}
```

执行代码输出：
```
# ./a.out 
A: begin
hello, i'm B
A: end
```

上述方案有两个问题，性能和扩展性。主线程自选检查会浪费 CPU 时间，多线程等待更甚。

### 条件变量实现等待
线程可以使用条件变量，来等待一个条件成真。条件变量是一个显示队列，当某些条件不满足时，线程可以把自己加入队列，等待该条件。另外某个线程，当它改变了上述状态时，就可以唤醒一个或多个线程。

条件变量的类型是 `pthread_cond_t`，有 `wait()` 和 `single()` 两种操作。线程调用 `wait()` 进入休眠，当线程想唤醒等待在某个条件变量上睡眠的线程时，调用 `single()`。

条件变量本身是由互斥量保护的，线程在改变条件状态之前必须首先锁住互斥量。

- 条件变量是临界资源，那么修改临界资源首先要加锁。

- 线程在条件不满足之后，调用 wait() 进入阻塞休眠并释放锁，等待其它线程获取锁修改临界资源。

- 当线程被唤醒后，它会重新尝试获取锁。只有在重新获锁后，线程才会从 wait() 返回并继续执行。

示例代码：
```c
#include <stdio.h>
#include <pthread.h>

int done = 0;
pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t c = PTHREAD_COND_INITIALIZER;

void thr_exit() {
    pthread_mutex_lock(&m);
    done = 1;
    pthread_cond_signal(&c);
    pthread_mutex_unlock(&m);
}

void *child(void *arg) {
    printf("hellom i'm %s\n", arg);
    thr_exit();
    return NULL;
}

void thr_join() {
    pthread_mutex_lock(&m);
    while(done == 0)
        pthread_cond_wait(&c, &m);
    pthread_mutex_unlock(&m);
}

int main() {
    printf("parent: begin\n");
    pthread_t p;
    pthread_create(&p, NULL, child, "B");
    thr_join();
    printf("parent: end\n");
    return 0;
}
```

wait() 调用有一个参数是互斥量，它假定 wait() 调用时这个互斥量是已上锁状态，wait() 调用会释放锁并让调用线程休眠。wait() 调用返回时，互斥量再次被锁住。

while 循环是有意义的，首先是解决了虚假唤醒的问题，线程在没有接收到通知的情况下从 wait 返回，虽然这个问题不常见；另一种情况是多个消费者被唤醒，如果其中一个消费者消费消息使队列为空，那么其它线程要重新检查队列，可能再次为空，因此需要继续等待。

互斥量的使用也是有意义的，没有互斥量的情况下，如果父线程在检查完条件在 wait() 调用之前，此时切换了子线程执行，子线程修改了变量 done 为 1，发出信号，同样没有等待线程。父线程再次运行时，就会长眠不醒了。

!!! note "条件变量调用 single 和 wait 时要持有锁！"

### 生产消费模型
条件变量一个有用的场景就是生产者和消费者模型，生产消费模型有几个要求:  

- 能够正确的并发访问。
- 如果生产满了，那么生产者要阻塞休眠，直到有消费者消费了消息，然后唤醒生产者。
- 如果消费空了，那么消费者要阻塞休眠，直到有生产者生产了消息，然后唤醒消费着。

示例代码：
```c
#include <pthread.h>

int buffer[MAX];
int fill = 0;
int use = 0;
int count = 0;

void put(int value)
{
    buffer[fill] = value;
    fill = (fill + 1) % MAX;
    count++;
}

int get()
{
    int tmp = buffer[use];
    use = (use + 1) % MAX;
    count--;
    return tmp;
}

pthread_cond_t empty, fill;
mutex_t mutex;

void *producer(void *arg) {
    int i;
    for(i = 0; i < loops; i ++) {
        pthread_mutex_lock(&mutex);
        while(count == MAX) {
            pthread_cond_wait(&empty, &mutex);
        }
        put(i);
        pthread_cond_signal(&fill);
        pthread_mutex_unlock(&mutex);
    }
}

void *consume(void *arg) {
    int i;
    for(i = 0; i < loops; i ++) {
        pthread_mutex_lock(&mutex);
        while(count == 0) {
            pthread_cond_wait(&fill, &mutex);
        }
        int tmp = get();
        pthread_cond_signal(&empty);
        pthread_mutex_unlock(&mutex);
        printf("%d\n", tmp);
    }
}
```

## 信号量
信号量是有一个整数值的对象，信号量的声明和初始化：
```c
#include <semaphore.h>

sem_t s
sem_init(&s, 0, 1);
```
初始化第一个参数为信号量，第二个参数设置为 0，表示信号量在同意进程的多个线程是共享的，第三个参数将信号量的初始值设置为 1。

可以用两个函数来操作信号量。在 POSIX 标准中，是 sem_wait() 和 sem_post()。首先，sem_wait() 会将信号量的值减去 1，如果结果大于等于 0，则 sem_wait() 立刻返回，否则会让调用线程挂起。sem_post() 直接增加信号量的值，如果有等待线程，则唤醒其中一个。当信号量的值为负数时，这个值就是等待线程的个数。

### 二值信号量
二值信号量将信号量的值初始化为 1，二值信号量和互斥量（锁）在语义上是等价的。

### 信号量实现等待
示例代码：
```c
#include <stdio.h>
#include <pthread.h>
#include <semaphore.h>

sem_t s;

void *child(void *arg) {
	printf("hello, i'm %s\n", arg);
	sem_post(&s);
	return NULL;
}

int main() {
    sem_init(&s, 0, 0);
    printf("parent: begin\n");
    pthread_t c;
    pthread_create(&c, NULL, child, "B");
    sem_wait(&s);
    printf("parent: end\n");
    return 0;
}
```

无论是父线程还是子线程先执行，都会输出如下结果：
```
# ./a.out 
parent: begin
hello, i'm B
parent: end
```



## QA
1. 如何实现可重入的锁？

2. 为什么汇编指令需要加上 `LOCK` 前缀？临界区的状态变更如何保证全局可视？

4. 如何实现读写锁？

5. Java 通过锁能够实现互斥访问，但是执行完临界区的代码之后如何保证全局变量的可视性？

    如果一个线程解锁，那么紧跟着加锁的线程是能够看到上一个线程的改变的，由 Happen-before 规则约束。
    那么 Happen-before 底层又是如果实现的呢？https://gee.cs.oswego.edu/dl/jmm/cookbook.html

5. Java 对象头的结构是什么？在由无锁->轻量级锁->重量级锁过程中 CAS 的参数是什么？如何获取这些参数？