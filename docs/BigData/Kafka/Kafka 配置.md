Controller 是 Kafka 集群的一个节点，管理协调 Kafka 集群。

Broker 是 Kafka 集群的一个节点，对外提服务。

Topic 主题，一个 Kafka 集群可以包含很多的主题。

Partition 区，一个主题可以有多个分区，每个分区包含主题中的一部分数据。分区可以配置存储多份，包括原始数据在内都称为副本。同一时间只有一个副本提供服务，称为 Leader 副本；其余的副本称为 Folloer 副本，提供数据备份功能。

Consumer Group 是消费者组，消费者属于消费者组。一个消费者组会完整的消费一个主题的数据，具体由消费者消费分区的数据实现。同一个消费者组的每个消费者可以消费零到多个分区的数据，但是不能多个消费者同时消费一个分区的数据。

![[Kafka-ConsumerGroup.png]]
## 生产者配置
Kafka 生产者有两个线程（假设 Main 线程和 Sender 线程），一个内存池缓存发送的数据。

假设 send(msg) 方法在 Main 线程调用，消息会经历拦截器、序列化器、分区器，然后消息会存储在内存池中。Sender 线程负责读取缓存的数据发送到 Kafka。

buffer.memory 控制缓冲区的容量，默认 32MB。如果缓冲区满了，max.blocks.ms 控制 Main 线程写入到缓冲区的阻塞时间。
缓冲区里面是多个队列，每个 topic 的分区都对应一个队列。队列中的多个消息可以组成一个批次，batch.size 控制批次的大小。如果消息批次达到 batch.size 则整批次的消息会发送到 Kafka。如果一批次的消息大小未达到 batch.size，可能会因为超时 linger.ms 而提前发送，linger.ms 默认为 0，消息立即发送。

buffer-available-bytes 用来监控缓冲区的情况。
compression.type=gzip 可以启用消息压缩，减少缓冲区的占用。

## 消费者配置
**auto.offset.reset**
该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长 时间失效，包含偏移量的记录已经过时并被删除）该作何处理。它的默认值是 `latest`，意思是说，在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）。另一个值是 `earliest`，意思是说，在偏移量无效的情况下，消费者将从起始位置读取分区的记录。

**enable.auto.commit** 
该属性指定了消费者是否自动提交偏移量，默认值是 true。为了尽量避免出现重复数据和数据丢失，可以把它设为 false，由自己控制何时提交偏移量。如果把它设为 true，还可以通过配置 `auto.commit.interval.ms` 属性来控制提交的频率。

Kafka 消费者通过 poll() 拉取分区里面的消息进行消费，默认情况消费者默认不需要确认消费，而是每过一段时间把自己从 poll() 接收到的最大偏移量提交上去（有可能已经提交了偏移量，但是还没有消费处理完成）。自动提交由 `enable.auto.commit` 控制，频率由 `auto.commit.interval.ms` 控制，默认 5s。

重复消费的情况，如果上一次提交偏移量之后，消费者又消费了一些消息但是还没有来得及提交，消费者重启会导致 poll() 拉取已经消费过的消息。

消息丢失的情况，如果上一次提交偏移量之后，消费者还没消费完偏移量之前的消息，消费者重启 poll() 只会拉取偏移量之后的消息，导致消息丢失。

关闭 `enable.auto.commit`，使用 `commitSync()` 方法进行同步手动提交，能够解决消息丢失的问题。但是仍不能避免消息重复的问题，因为提交有可能失败，导致重复消费。